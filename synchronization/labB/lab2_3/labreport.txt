2.3 Реализуйте односвязный список, хранящий строки длиной менее 100 символов, у
    которого с каждым элементом связан отдельный примитив синхронизации (за основу
    можно взять реализацию списка, на котором построена очередь queue_t). Объявление
    такого списка может выглядеть, например, так:
        typedef struct _Node {
            char value[100];
            struct _Node* next;
            pthread_mutex_t sync;
        } Node;
        
        typedef struct _Storage {
            Node *first;
        } Storage;

    Первый поток пробегает по всему хранилищу и ищет количество пар строк, идущих по
    возрастанию длины. Как только достигнут конец списка, поток инкрементирует
    глобальную переменную, в которой хранится, количество выполненных им итераций и
    сразу начинает новый поиск.

    Второй поток пробегает по всему хранилищу и ищет количество пар строк, идущих по
    убыванию длины. Как только достигнут конец списка, поток инкрементирует
    глобальную переменную, в которой хранится количество выполненных им итераций и
    сразу начинает новый поиск.
    
    Третий поток пробегает по всему хранилищу и ищет количество пар строк, имеющих
    одинаковую длину. Как только достигнут конец списка, поток инкрементирует
    глобальную переменную, в которой хранится количество выполненных им итераций и
    сразу начинает новый поиск.

    Запускает 3 потока, которые в непрерывном бесконечном цикле случайным образом
    проверяют - требуется ли переставлять соседние элементы списка (не значения) и
    выполняют перестановку. Каждая успешная попытка перестановки фиксируется в
    соответствующей глобальной переменной-счетчике.

    Используйте для синхронизации доступа к элементам списка спинлоки, мутексы и
    блокировки чтения-записи. Понаблюдайте как изменяются (и изменяются ли) значения
    переменных счетчиков и объясните результат. Проверьте для списков длины 100, 1000,
    10000, 100000.

    При реализации обратите внимание на следующие пункты:
    - продумайте ваше решение, чтобы избежать ошибок соревнования.
    - необходимо блокировать все записи с данными которых производится работа.
    - при перестановке записей списка, необходимо блокировать три записи.
    - чтобы избежать мертвых блокировок, примитивы записей, более близких к началу
    списка, всегда захватывайте раньше.



Для синхронизации доступа к элементам списка использую: 
    1) мьютексы
        pthread_mutex_init
            int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr);
                mutex - указатель на объект типа pthread_mutex_t, который будет инициализирован как мьютекс.
                attr - указатель на объект типа pthread_mutexattr_t, содержащий атрибуты мьютекса. 

            инициализирует мьютекс, используя атрибуты, указанные объектом атрибутов мьютекса attr. 
                Если attr равен NULL, то мьютекс инициализируется с атрибутами по умолчанию (см. pthread_mutexattr_init()). 
                После инициализации мьютекс находится в разблокированном состоянии.

            в моем случае: 
                queue_t* queue_init(int max_count) {
                    ...
                    pthread_mutex_init(&q->lock, NULL);
                    ...
                }
            
            https://help.kpda.ru/neutrino/2020/help/index.jsp?topic=%2Fru.kpda.doc.os_ru%2Fhtml%2Flibraries%2Flibc%2Fp%2Fpthread_mutex_init.html
            https://www.opennet.ru/cgi-bin/opennet/man.cgi?topic=pthread_mutex_init
        
        pthread_mutex_lock
            int pthread_mutex_lock( pthread_mutex_t *mutex );
                mutex - указатель на объект типа pthread_mutex_t, который будет заблокирован.

            блокирует мьютекс mutex. Если мьютекс уже заблокирован, то вызывающий поток блокируется до тех пор, 
                пока он не захватит мьютекс. По возвращении из функции, объект мьютекса блокируется и принадлежит 
                вызывающему потоку.

            в моем случае:
                int queue_add(queue_t *q, int val) {
                    pthread_mutex_lock(&q->lock);
                    ...
                }
            
            https://help.kpda.ru/neutrino/2020/help/index.jsp?topic=%2Fru.kpda.doc.os_ru%2Fhtml%2Flibraries%2Flibc%2Fp%2Fpthread_mutex_init.html
            https://www.opennet.ru/man.shtml?topic=pthread_mutex_lock&category=3&russian=1

        pthread_mutex_unlock
            int pthread_mutex_unlock( pthread_mutex_t *mutex );
                mutex - указатель на объект типа pthread_mutex_t, который будет разблокирован.

            в моем случае: 
                int queue_add(queue_t *q, int val) {
                    ...
                    pthread_mutex_unlock(&q->lock);
                }

            разблокирует мьютекс mutex. Мьютекс должен принадлежать вызывающему потоку. Если в мьютексе есть 
                заблокированные потоки, ожидающий поток с наивысшим приоритетом разблокируется и становится 
                следующим владельцем мьютекса.

            https://help.kpda.ru/neutrino/2020/help/index.jsp?topic=%2Fru.kpda.doc.os_ru%2Fhtml%2Flibraries%2Flibc%2Fp%2Fpthread_mutex_init.html
            https://www.opennet.ru/cgi-bin/opennet/man.cgi?topic=pthread_mutex_unlock

        разбор кода (queue1.h, queue1.c, main1.c):
            queue1.c:
                Storage *init_storage(int capacity) 
                    создаёт и возвращает пустой Storage, готовый к заполнению узлами в будущем.

                    запрашиваю у кучи sizeof(Storage) байт. Если malloc() вернёт NULL, печатаю сообщение об 
                        ошибке и делаю exit(), чтобы не продолжить в неопределённом состоянии:
                        Storage *storage = (Storage*)malloc(sizeof(Storage));
                        if (!storage) {
                            printf("malloc() failed to allocate memory for a queue\n");
                            exit(EXIT_FAILURE);
                        }
                    поле storage->sync - мьютекс для защиты критических участков хранилища. Инициализирую его:
                        pthread_mutex_init(&(storage->sync), NULL);
                    задаю параметры хранилища:
                        storage->capacity = capacity;
                        storage->first = NULL;
                    возвращаю ссылку на созданное хранилище, в которое можно добавлять узлы с помощью add_node() и/или fill_storage():
                        return storage;

                Node *create_node(const char *value)
                    выделяет на куче память для одиночного элемента списка.

                    запрашиваю у кучи sizeof(Node) байт. calloc() установит все биты в 0. 
                        Если malloc() вернёт NULL, печатаю сообщение об ошибке и делаю exit(), 
                        чтобы не продолжить в неопределённом состоянии:
                        Node *new_node = (Node *) calloc(1, sizeof(*new_node));
                        if (!new_node) {
                            printf("malloc() failed to allocate memory for a new node\n");
                            exit(EXIT_FAILURE);
                        }
                    переношу содержимое строки value в поле value нового узла:
                        strcpy(new_node->value, value);
                    каждый узел имеет свой собственный мьютекс sync, который нужно инициализировать отдельным вызовом: 
                        pthread_mutex_init(&(new_node->sync), NULL);
                    возвращаю ссылку на созданный узел:
                        return new_node;

                void add_node(Storage *storage, const char *value)
                    вставляет созданный узел в хвост односвязного списка.

                    выделяю на куче память для одиночного элемента списка, который и буду вставлять в список:
                        Node *new_node = create_node(value);
                    если список пустой (только создан), то голову проставляю на новый узел. А если не пустой,
                        то завожу временный указатель на голову node и прохожу по всем нодам, пока не дойду
                        до последнего (node->next). Последнему узлу присваиваю указатель на новый узел:             
                        if (storage->first != NULL) {
                            Node *node = storage->first;
                            while (node->next != NULL) {
                                node = node->next;
                            }
                            node->next = new_node;
                        } else {
                            storage->first = new_node;
                        }

                void fill_storage(Storage *storage)
                    заполняет список строковыми представлениями чисел от 1 до storage->capacity.

                    выделяю буфер в который буду писать строку с цифрами:
                        char buff[24];
                    по каждому значению от 1 до storage->capacity записываю текстовое представление 
                        числа в buff и создаю узел со строкой buff + цепляю его в конец списка: 
                        for (int i = 1; i <= storage->capacity; ++i) {
                            sprintf(buff, "%d", i % (storage->capacity + 1));
                            add_node(storage, buff);
                        }

            main1.c:
                int main()

                void *count_monitor(void *arg)
                    вечно ежесекундно пробегает по всему списку и выводит накопленные счетчики по 
                        каждому узлу, а затем суммарные значения.

                void *compare_length_thread(void *data)
                    функция запускается в 3 экземплярах (1 на каждый тип сравнения: ASC, DESC, EQ). 
                        Её задача - бегать по списку, сравнивать попарно у текущего узла и следующего 
                        длины строк и в зависимости от типа сравнения инкрементировать соответствующий 
                        счётчик пока не прошли все узлы списка.

                    извлекаю из параметра data указатель на списко и тип сравнения:
                        ThreadData *thread_data = (ThreadData *)data;
                        Storage *storage = thread_data->storage;
                        int type = thread_data->type;
                    перебираю список, блокирую мьютекс списка чтобы извлечь storage->first:
                        while (1) {
                            Node *curr1;
                            pthread_mutex_lock(&storage->sync);
                    получаю первый узел списка и блокирую его, чтобы никто не менял его поля:       
                            if((curr1 = storage->first) == NULL) {
                                printf("compare_length_thread(): curr1 is NULL\n");
                                pthread_mutex_unlock(&storage->sync);
                                break;
                            }
                            pthread_mutex_lock(&curr1->sync);
                    освобождаю мьютекс списка ибо он больше не нужен, так как работаю с узловыми мьютексами:
                            pthread_mutex_unlock(&storage->sync);
                    здесь сравниваю длину значений у узла curr1 и следующего за ним. После этого 
                        сдвигаем указатели: теперь curr2 - текущий узел, и буду сравнивать его с следующим: 
                            Node *curr2 = curr1->next;
                            while (curr2 != NULL) {
                                pthread_mutex_lock(&curr2->sync);
                                update_counter(curr1, curr2, type);
                                pthread_mutex_unlock(&curr1->sync);
                                curr1 = curr2;
                                curr2 = curr1->next;
                            }
                    когда curr2 стал NULL (конец списка), остаётся только один захваченный мьютекс на curr1. 
                        снимаю его и прогоняю процесс заново:
                            pthread_mutex_unlock(&curr1->sync);

                void swap_nodes(Node **curr1_next, Node *curr2, Node *curr3)
                    меняет местами узлы curr2 и curr3. те: 
                    было: ... -> *curr1_next -> curr2 -> curr3 -> ...
                    стало: ... -> *curr1_next -> curr3 -> curr2 -> ...

                    инкременирую счётчик успешных перестановок в curr2 - фиксирую что этот узел ушёл вперёд на одну позицию:
                        ++curr2->counter_swap;
                    предыдущий curr2 элемент указывает на следующий за ним (видно на рисунке "стало сверху"). 
                        curr2 указывает на следующий за curr3. curr3 указывает на curr2: 
                        *curr1_next = curr3;
                        curr2->next = curr3->next;
                        curr3->next = curr2;

                void *swap_thread(void *data)
                    логика работы аналогична compare_length_thread(). Поэтому проговорю устно: берем мьютекс списка, 
                        с проверкой извлекаем первый узел и берем его мьютекс, 
                        с проверкой относительно первого узла извлекаем второй узел и берем его мьютекс,
                        с вероятностью 50% меняем местами узлы curr1 и curr2 и обновляю curr1 и curr2 в соответствии с новым порядком, 
                        отдаю мьютекс списка так как теперь работаю с мьютексами узлов а не всего списка,
                        беру curr3 как curr2->next, 
                        далее по циклу до конца списка делаю 50% свап узлов: 
                        с вероятностью 50% меняем местами узлы curr2 и curr3 - после этого curr3 идет за curr1 - 
                            можно снять мьютекс с прежнего curr1 (мы сдвигаемся и работаем теперь с curr2 и curr3). 

    2) спинлоки (queue2.h, queue2.c, main2.c):
        queue2.c:

        main2.c:
    
    3) блокировки чтения-записи
